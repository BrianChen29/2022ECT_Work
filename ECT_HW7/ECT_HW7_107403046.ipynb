{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECT_HW7_107403046\n",
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.132786</td>\n",
       "      <td>0.079557</td>\n",
       "      <td>0.119090</td>\n",
       "      <td>0.067958</td>\n",
       "      <td>0.209592</td>\n",
       "      <td>0.141634</td>\n",
       "      <td>1.932562</td>\n",
       "      <td>8.308895</td>\n",
       "      <td>0.963181</td>\n",
       "      <td>0.738307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132786</td>\n",
       "      <td>0.110132</td>\n",
       "      <td>0.017112</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.298222</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.726562</td>\n",
       "      <td>2.718750</td>\n",
       "      <td>0.125160</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.150762</td>\n",
       "      <td>0.074463</td>\n",
       "      <td>0.160106</td>\n",
       "      <td>0.092899</td>\n",
       "      <td>0.205718</td>\n",
       "      <td>0.112819</td>\n",
       "      <td>1.530643</td>\n",
       "      <td>5.987498</td>\n",
       "      <td>0.967573</td>\n",
       "      <td>0.762638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150762</td>\n",
       "      <td>0.105945</td>\n",
       "      <td>0.026230</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.479620</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.312500</td>\n",
       "      <td>5.304688</td>\n",
       "      <td>0.123992</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.076767</td>\n",
       "      <td>0.144337</td>\n",
       "      <td>0.110532</td>\n",
       "      <td>0.231962</td>\n",
       "      <td>0.121430</td>\n",
       "      <td>1.397156</td>\n",
       "      <td>4.766611</td>\n",
       "      <td>0.959255</td>\n",
       "      <td>0.719858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.093052</td>\n",
       "      <td>0.017758</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.301339</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.283937</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.142239</td>\n",
       "      <td>0.078018</td>\n",
       "      <td>0.138587</td>\n",
       "      <td>0.088206</td>\n",
       "      <td>0.208587</td>\n",
       "      <td>0.120381</td>\n",
       "      <td>1.099746</td>\n",
       "      <td>4.070284</td>\n",
       "      <td>0.970723</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142239</td>\n",
       "      <td>0.096729</td>\n",
       "      <td>0.017957</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.336476</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.164062</td>\n",
       "      <td>2.156250</td>\n",
       "      <td>0.148272</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.134329</td>\n",
       "      <td>0.080350</td>\n",
       "      <td>0.121451</td>\n",
       "      <td>0.075580</td>\n",
       "      <td>0.201957</td>\n",
       "      <td>0.126377</td>\n",
       "      <td>1.190368</td>\n",
       "      <td>4.787310</td>\n",
       "      <td>0.975246</td>\n",
       "      <td>0.804505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134329</td>\n",
       "      <td>0.105881</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.340365</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>4.695312</td>\n",
       "      <td>4.679688</td>\n",
       "      <td>0.089920</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "5  0.132786  0.079557  0.119090  0.067958  0.209592  0.141634   1.932562   \n",
       "6  0.150762  0.074463  0.160106  0.092899  0.205718  0.112819   1.530643   \n",
       "7  0.160514  0.076767  0.144337  0.110532  0.231962  0.121430   1.397156   \n",
       "8  0.142239  0.078018  0.138587  0.088206  0.208587  0.120381   1.099746   \n",
       "9  0.134329  0.080350  0.121451  0.075580  0.201957  0.126377   1.190368   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "5     8.308895  0.963181  0.738307  ...  0.132786  0.110132  0.017112   \n",
       "6     5.987498  0.967573  0.762638  ...  0.150762  0.105945  0.026230   \n",
       "7     4.766611  0.959255  0.719858  ...  0.160514  0.093052  0.017758   \n",
       "8     4.070284  0.970723  0.770992  ...  0.142239  0.096729  0.017957   \n",
       "9     4.787310  0.975246  0.804505  ...  0.134329  0.105881  0.019300   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "5  0.253968  0.298222  0.007812  2.726562  2.718750  0.125160   male  \n",
       "6  0.266667  0.479620  0.007812  5.312500  5.304688  0.123992   male  \n",
       "7  0.144144  0.301339  0.007812  0.539062  0.531250  0.283937   male  \n",
       "8  0.250000  0.336476  0.007812  2.164062  2.156250  0.148272   male  \n",
       "9  0.262295  0.340365  0.015625  4.695312  4.679688  0.089920   male  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv('gender_recog.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>0.205177</td>\n",
       "      <td>0.046889</td>\n",
       "      <td>0.212767</td>\n",
       "      <td>0.204628</td>\n",
       "      <td>0.227744</td>\n",
       "      <td>0.023116</td>\n",
       "      <td>3.695067</td>\n",
       "      <td>18.903910</td>\n",
       "      <td>0.849017</td>\n",
       "      <td>0.291601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205177</td>\n",
       "      <td>0.201443</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.405273</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.830078</td>\n",
       "      <td>0.825195</td>\n",
       "      <td>0.447616</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0.167356</td>\n",
       "      <td>0.059299</td>\n",
       "      <td>0.184629</td>\n",
       "      <td>0.147614</td>\n",
       "      <td>0.206526</td>\n",
       "      <td>0.058912</td>\n",
       "      <td>2.359220</td>\n",
       "      <td>9.367843</td>\n",
       "      <td>0.933728</td>\n",
       "      <td>0.579145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167356</td>\n",
       "      <td>0.161590</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.171402</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.187952</td>\n",
       "      <td>0.065855</td>\n",
       "      <td>0.203059</td>\n",
       "      <td>0.132068</td>\n",
       "      <td>0.245099</td>\n",
       "      <td>0.113031</td>\n",
       "      <td>1.480657</td>\n",
       "      <td>5.018319</td>\n",
       "      <td>0.934454</td>\n",
       "      <td>0.582426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187952</td>\n",
       "      <td>0.111375</td>\n",
       "      <td>0.019704</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.519737</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>2.843750</td>\n",
       "      <td>2.781250</td>\n",
       "      <td>0.176030</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3026</th>\n",
       "      <td>0.217800</td>\n",
       "      <td>0.045799</td>\n",
       "      <td>0.224264</td>\n",
       "      <td>0.204146</td>\n",
       "      <td>0.242403</td>\n",
       "      <td>0.038257</td>\n",
       "      <td>2.175078</td>\n",
       "      <td>7.668994</td>\n",
       "      <td>0.868693</td>\n",
       "      <td>0.256959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217800</td>\n",
       "      <td>0.223417</td>\n",
       "      <td>0.013021</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.517782</td>\n",
       "      <td>0.214844</td>\n",
       "      <td>0.825195</td>\n",
       "      <td>0.610352</td>\n",
       "      <td>0.435556</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0.195947</td>\n",
       "      <td>0.063271</td>\n",
       "      <td>0.214076</td>\n",
       "      <td>0.134329</td>\n",
       "      <td>0.253063</td>\n",
       "      <td>0.118734</td>\n",
       "      <td>1.298973</td>\n",
       "      <td>4.016681</td>\n",
       "      <td>0.921747</td>\n",
       "      <td>0.461691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195947</td>\n",
       "      <td>0.119255</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.509673</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>4.109375</td>\n",
       "      <td>3.984375</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>0.151091</td>\n",
       "      <td>0.066940</td>\n",
       "      <td>0.147940</td>\n",
       "      <td>0.099045</td>\n",
       "      <td>0.212299</td>\n",
       "      <td>0.113254</td>\n",
       "      <td>1.047134</td>\n",
       "      <td>6.083770</td>\n",
       "      <td>0.970128</td>\n",
       "      <td>0.725125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151091</td>\n",
       "      <td>0.179934</td>\n",
       "      <td>0.048436</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>1.493304</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>7.804688</td>\n",
       "      <td>7.781250</td>\n",
       "      <td>0.103473</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>0.189874</td>\n",
       "      <td>0.058942</td>\n",
       "      <td>0.197333</td>\n",
       "      <td>0.139733</td>\n",
       "      <td>0.251733</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>1.687032</td>\n",
       "      <td>6.720521</td>\n",
       "      <td>0.913219</td>\n",
       "      <td>0.367184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189874</td>\n",
       "      <td>0.111458</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.888338</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>3.960938</td>\n",
       "      <td>3.937500</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>0.178187</td>\n",
       "      <td>0.043849</td>\n",
       "      <td>0.162732</td>\n",
       "      <td>0.151186</td>\n",
       "      <td>0.203144</td>\n",
       "      <td>0.051959</td>\n",
       "      <td>3.434020</td>\n",
       "      <td>17.779892</td>\n",
       "      <td>0.865041</td>\n",
       "      <td>0.282078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178187</td>\n",
       "      <td>0.158932</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.925532</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>3.679688</td>\n",
       "      <td>3.656250</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.177619</td>\n",
       "      <td>0.058199</td>\n",
       "      <td>0.190947</td>\n",
       "      <td>0.159595</td>\n",
       "      <td>0.210459</td>\n",
       "      <td>0.050864</td>\n",
       "      <td>2.572171</td>\n",
       "      <td>10.823046</td>\n",
       "      <td>0.926339</td>\n",
       "      <td>0.553794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177619</td>\n",
       "      <td>0.160545</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.325758</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.156250</td>\n",
       "      <td>5.148438</td>\n",
       "      <td>0.083656</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>0.206083</td>\n",
       "      <td>0.034759</td>\n",
       "      <td>0.197590</td>\n",
       "      <td>0.189398</td>\n",
       "      <td>0.227470</td>\n",
       "      <td>0.038072</td>\n",
       "      <td>4.002841</td>\n",
       "      <td>23.981710</td>\n",
       "      <td>0.830987</td>\n",
       "      <td>0.200364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206083</td>\n",
       "      <td>0.177252</td>\n",
       "      <td>0.046921</td>\n",
       "      <td>0.277457</td>\n",
       "      <td>0.559896</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>1.406250</td>\n",
       "      <td>1.382812</td>\n",
       "      <td>0.161017</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "3013  0.205177  0.046889  0.212767  0.204628  0.227744  0.023116  3.695067   \n",
       "1992  0.167356  0.059299  0.184629  0.147614  0.206526  0.058912  2.359220   \n",
       "379   0.187952  0.065855  0.203059  0.132068  0.245099  0.113031  1.480657   \n",
       "3026  0.217800  0.045799  0.224264  0.204146  0.242403  0.038257  2.175078   \n",
       "404   0.195947  0.063271  0.214076  0.134329  0.253063  0.118734  1.298973   \n",
       "2471  0.151091  0.066940  0.147940  0.099045  0.212299  0.113254  1.047134   \n",
       "1080  0.189874  0.058942  0.197333  0.139733  0.251733  0.112000  1.687032   \n",
       "2687  0.178187  0.043849  0.162732  0.151186  0.203144  0.051959  3.434020   \n",
       "1993  0.177619  0.058199  0.190947  0.159595  0.210459  0.050864  2.572171   \n",
       "2911  0.206083  0.034759  0.197590  0.189398  0.227470  0.038072  4.002841   \n",
       "\n",
       "           kurt    sp.ent       sfm   ...    centroid   meanfun    minfun  \\\n",
       "3013  18.903910  0.849017  0.291601   ...    0.205177  0.201443  0.063694   \n",
       "1992   9.367843  0.933728  0.579145   ...    0.167356  0.161590  0.017917   \n",
       "379    5.018319  0.934454  0.582426   ...    0.187952  0.111375  0.019704   \n",
       "3026   7.668994  0.868693  0.256959   ...    0.217800  0.223417  0.013021   \n",
       "404    4.016681  0.921747  0.461691   ...    0.195947  0.119255  0.029197   \n",
       "2471   6.083770  0.970128  0.725125   ...    0.151091  0.179934  0.048436   \n",
       "1080   6.720521  0.913219  0.367184   ...    0.189874  0.111458  0.048000   \n",
       "2687  17.779892  0.865041  0.282078   ...    0.178187  0.158932  0.048387   \n",
       "1993  10.823046  0.926339  0.553794   ...    0.177619  0.160545  0.015686   \n",
       "2911  23.981710  0.830987  0.200364   ...    0.206083  0.177252  0.046921   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx   label  \n",
       "3013  0.250000  0.405273  0.004883  0.830078  0.825195  0.447616  female  \n",
       "1992  0.271186  0.171875  0.007812  0.382812  0.375000  0.171402  female  \n",
       "379   0.181818  0.519737  0.062500  2.843750  2.781250  0.176030    male  \n",
       "3026  0.277778  0.517782  0.214844  0.825195  0.610352  0.435556  female  \n",
       "404   0.210526  0.509673  0.125000  4.109375  3.984375  0.082353    male  \n",
       "2471  0.279070  1.493304  0.023438  7.804688  7.781250  0.103473  female  \n",
       "1080  0.279070  0.888338  0.023438  3.960938  3.937500  0.166667    male  \n",
       "2687  0.279070  0.925532  0.023438  3.679688  3.656250  0.092105  female  \n",
       "1993  0.271186  0.325758  0.007812  5.156250  5.148438  0.083656  female  \n",
       "2911  0.277457  0.559896  0.023438  1.406250  1.382812  0.161017  female  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.sample(frac=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3168 entries, 2550 to 1077\n",
      "Data columns (total 21 columns):\n",
      "meanfreq    3168 non-null float64\n",
      "sd          3168 non-null float64\n",
      "median      3168 non-null float64\n",
      "Q25         3168 non-null float64\n",
      "Q75         3168 non-null float64\n",
      "IQR         3168 non-null float64\n",
      "skew        3168 non-null float64\n",
      "kurt        3168 non-null float64\n",
      "sp.ent      3168 non-null float64\n",
      "sfm         3168 non-null float64\n",
      "mode        3168 non-null float64\n",
      "centroid    3168 non-null float64\n",
      "meanfun     3168 non-null float64\n",
      "minfun      3168 non-null float64\n",
      "maxfun      3168 non-null float64\n",
      "meandom     3168 non-null float64\n",
      "mindom      3168 non-null float64\n",
      "maxdom      3168 non-null float64\n",
      "dfrange     3168 non-null float64\n",
      "modindx     3168 non-null float64\n",
      "label       3168 non-null object\n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 544.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = df.drop(['label'], axis = 1)\n",
    "y = df['label']#要預測欄位\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3)#, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RFmodel = RandomForestClassifier(n_estimators=100)\n",
    "RFmodel.fit(X_train, y_train)\n",
    "\n",
    "#y_pred = RFmodel.predict(X_test)\n",
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9375     0.96842105 0.97894737 0.92631579 1.         0.94736842\n",
      " 0.95789474 0.97894737 0.94736842 0.94736842]\n",
      "0.959013157894737\n"
     ]
    }
   ],
   "source": [
    "RFscores = cross_val_score(RFmodel,X_test,y_test,cv=10,scoring='f1_micro')\n",
    "print(RFscores)\n",
    "print(RFscores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(4, 4), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLPmodel = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(4,4), random_state=1)\n",
    "MLPmodel.fit(X_train, y_train)\n",
    "\n",
    "#y_pred = MLPmodel.predict(X_test)\n",
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88541667 0.82105263 0.84210526 0.89473684 0.82105263 0.91578947\n",
      " 0.85263158 0.94736842 0.93684211 0.85263158]\n",
      "0.8769627192982457\n"
     ]
    }
   ],
   "source": [
    "MLPscores = cross_val_score(MLPmodel,X_test,y_test,cv=10,scoring='f1_micro')\n",
    "print(MLPscores)\n",
    "print(MLPscores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 1s 3ms/step - loss: 3.0514 - precision: 0.4871 - recall: 0.4634 - auc: 0.4824\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.3841 - precision: 0.5198 - recall: 0.4148 - auc: 0.5466\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.1496 - precision: 0.5481 - recall: 0.4211 - auc: 0.5743\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1973 - precision: 0.5485 - recall: 0.4280 - auc: 0.5684    \n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0021 - precision: 0.6075 - recall: 0.5442 - auc: 0.6258\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0981 - precision: 0.5715 - recall: 0.4994 - auc: 0.6064\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.1094 - precision: 0.5977 - recall: 0.5890 - auc: 0.6424\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9022 - precision: 0.6293 - recall: 0.5808 - auc: 0.6736\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9703 - precision: 0.6306 - recall: 0.6402 - auc: 0.6625\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8749 - precision: 0.6481 - recall: 0.6547 - auc: 0.7075\n",
      "99/99 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['male'],\n",
       "       ['male'],\n",
       "       ['male'],\n",
       "       ...,\n",
       "       ['male'],\n",
       "       ['male'],\n",
       "       ['male']], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def build_model(optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Dense(200, input_dim=20, kernel_initializer=\"he_normal\", activation=\"relu\")\n",
    "    )\n",
    "    model.add(Dense(100, kernel_initializer=\"he_normal\", activation=\"relu\"))\n",
    "    model.add(Dense(100, kernel_initializer=\"he_normal\", activation=\"relu\"))\n",
    "    model.add(Dense(100, kernel_initializer=\"he_normal\", activation=\"relu\"))\n",
    "    model.add(Dense(1, kernel_initializer=\"he_normal\", activation=\"sigmoid\"))\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\n",
    "            keras.metrics.Precision(name=\"precision\"),\n",
    "            keras.metrics.Recall(name=\"recall\"),\n",
    "            keras.metrics.AUC(name=\"auc\"),\n",
    "        ],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "Kclf = KerasClassifier(build_model, optimizer=\"rmsprop\", epochs=10, batch_size=300)\n",
    "Kclf.fit(X, y)\n",
    "Kclf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 2s 4ms/step - loss: 7.2652 - precision: 0.5467 - recall: 0.5318 - auc: 0.4978\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.4305 - precision: 0.5328 - recall: 0.6273 - auc: 0.5063\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.5569 - precision: 0.5320 - recall: 0.6432 - auc: 0.5196\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.4897 - precision: 0.4709 - recall: 0.4045 - auc: 0.5131\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6299 - precision: 0.5879 - recall: 0.4864 - auc: 0.5918\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.2419 - precision: 0.5200 - recall: 0.2659 - auc: 0.5544\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.7177 - precision: 0.5345 - recall: 0.6341 - auc: 0.5394\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1333 - precision: 0.6131 - recall: 0.6159 - auc: 0.6080\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8238 - precision: 0.6515 - recall: 0.5864 - auc: 0.6678\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4858 - precision: 0.5770 - recall: 0.5364 - auc: 0.5831\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 4.1429 - precision: 0.5167 - recall: 0.3531 - auc: 0.5173    \n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2505 - precision: 0.4985 - recall: 0.3850 - auc: 0.5079\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7638 - precision: 0.5072 - recall: 0.6424 - auc: 0.4801\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0790 - precision: 0.5191 - recall: 0.4328 - auc: 0.5586    \n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2901 - precision: 0.5213 - recall: 0.3349 - auc: 0.5602\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6699 - precision: 0.6140 - recall: 0.1595 - auc: 0.6086\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0703 - precision: 0.5567 - recall: 0.6150 - auc: 0.5697\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9443 - precision: 0.5797 - recall: 0.4556 - auc: 0.5987\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0432 - precision: 0.5648 - recall: 0.6651 - auc: 0.6026\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9788 - precision: 0.5941 - recall: 0.5034 - auc: 0.6280\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 5.0390 - precision: 0.5396 - recall: 0.6696 - auc: 0.4734\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.2186 - precision: 0.5237 - recall: 0.4442 - auc: 0.5314    \n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0112 - precision: 0.5586 - recall: 0.3192 - auc: 0.5774    \n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0269 - precision: 0.5294 - recall: 0.4219 - auc: 0.5561\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3108 - precision: 0.5568 - recall: 0.5357 - auc: 0.5637\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4355 - precision: 0.5526 - recall: 0.5982 - auc: 0.5487\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4517 - precision: 0.5975 - recall: 0.4308 - auc: 0.5850\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9172 - precision: 0.5898 - recall: 0.5938 - auc: 0.6077\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4461 - precision: 0.5234 - recall: 0.5246 - auc: 0.5372\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7824 - precision: 0.5691 - recall: 0.5424 - auc: 0.5523\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 7.0514 - precision: 0.5358 - recall: 0.5489 - auc: 0.4913\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.2850 - precision: 0.5675 - recall: 0.4578 - auc: 0.5782\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9504 - precision: 0.5314 - recall: 0.2444 - auc: 0.5680\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.3544 - precision: 0.5269 - recall: 0.4356 - auc: 0.5308\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8942 - precision: 0.5217 - recall: 0.4000 - auc: 0.5350\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5879 - precision: 0.5620 - recall: 0.4933 - auc: 0.5594\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6746 - precision: 0.5377 - recall: 0.4911 - auc: 0.5325\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6999 - precision: 0.6208 - recall: 0.5311 - auc: 0.5865\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3643 - precision: 0.5215 - recall: 0.4844 - auc: 0.5425\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7296 - precision: 0.5364 - recall: 0.5244 - auc: 0.5288\n",
      "WARNING:tensorflow:5 out of the last 109 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026ADAA5ABF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 6.6017 - precision: 0.5432 - recall: 0.6741 - auc: 0.5104\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0849 - precision: 0.5363 - recall: 0.4621 - auc: 0.4999    \n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9823 - precision: 0.5162 - recall: 0.4263 - auc: 0.5067    \n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7782 - precision: 0.4884 - recall: 0.4710 - auc: 0.4444\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7849 - precision: 0.5123 - recall: 0.4174 - auc: 0.5069\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5800 - precision: 0.4986 - recall: 0.3839 - auc: 0.4948\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2603 - precision: 0.5397 - recall: 0.3638 - auc: 0.5355\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0853 - precision: 0.5359 - recall: 0.3996 - auc: 0.5371\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7561 - precision: 0.5338 - recall: 0.5290 - auc: 0.5210\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2750 - precision: 0.5356 - recall: 0.3527 - auc: 0.5488    \n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026AD96F2AE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 5.2679 - precision: 0.5074 - recall: 0.6959 - auc: 0.4106\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.5313 - precision: 0.5233 - recall: 0.3536 - auc: 0.5283    \n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.5257 - precision: 0.5452 - recall: 0.4617 - auc: 0.5280\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0164 - precision: 0.5322 - recall: 0.5023 - auc: 0.5249\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.5528 - precision: 0.5256 - recall: 0.4392 - auc: 0.5253\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.2202 - precision: 0.5409 - recall: 0.3874 - auc: 0.5660    \n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9615 - precision: 0.5242 - recall: 0.5113 - auc: 0.5229\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9056 - precision: 0.5704 - recall: 0.5113 - auc: 0.5607\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9387 - precision: 0.6100 - recall: 0.2748 - auc: 0.6315\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7124 - precision: 0.5081 - recall: 0.6351 - auc: 0.5131\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 7.5043 - precision: 0.5054 - recall: 0.6386 - auc: 0.4679    \n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.0788 - precision: 0.5137 - recall: 0.5114 - auc: 0.5126    \n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0450 - precision: 0.5440 - recall: 0.3795 - auc: 0.5770    \n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9911 - precision: 0.5307 - recall: 0.4523 - auc: 0.5264\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1187 - precision: 0.5309 - recall: 0.4295 - auc: 0.5236\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1029 - precision: 0.5126 - recall: 0.4614 - auc: 0.5087\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4527 - precision: 0.5619 - recall: 0.4955 - auc: 0.5577\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5319 - precision: 0.4978 - recall: 0.5182 - auc: 0.5073\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0616 - precision: 0.5853 - recall: 0.3977 - auc: 0.6046\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6399 - precision: 0.5444 - recall: 0.6273 - auc: 0.5495\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 6.6603 - precision: 0.4734 - recall: 0.4221 - auc: 0.5062\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1764 - precision: 0.5252 - recall: 0.6591 - auc: 0.4700\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3209 - precision: 0.5524 - recall: 0.3928 - auc: 0.5741\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.9695 - precision: 0.5484 - recall: 0.4605 - auc: 0.5730\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8152 - precision: 0.5368 - recall: 0.4447 - auc: 0.5614\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2828 - precision: 0.5452 - recall: 0.3950 - auc: 0.5821\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8027 - precision: 0.4867 - recall: 0.3296 - auc: 0.5478    \n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4807 - precision: 0.5971 - recall: 0.5621 - auc: 0.6051\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4584 - precision: 0.5962 - recall: 0.4966 - auc: 0.6038\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6022 - precision: 0.5299 - recall: 0.6591 - auc: 0.5506\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 2s 4ms/step - loss: 5.0192 - precision: 0.5463 - recall: 0.5451 - auc: 0.5149\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.5409 - precision: 0.5610 - recall: 0.4044 - auc: 0.5510\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0126 - precision: 0.4959 - recall: 0.4022 - auc: 0.4967\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8340 - precision: 0.5275 - recall: 0.6747 - auc: 0.4737\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1054 - precision: 0.5371 - recall: 0.4615 - auc: 0.5487\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9945 - precision: 0.5521 - recall: 0.5011 - auc: 0.5319\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6574 - precision: 0.5701 - recall: 0.5363 - auc: 0.5519\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1335 - precision: 0.6361 - recall: 0.5033 - auc: 0.6067\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8766 - precision: 0.5461 - recall: 0.6769 - auc: 0.5435\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6213 - precision: 0.6253 - recall: 0.5429 - auc: 0.6257\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 6.3643 - precision: 0.4906 - recall: 0.4643 - auc: 0.4783\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9108 - precision: 0.5277 - recall: 0.3616 - auc: 0.5287    \n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6641 - precision: 0.5244 - recall: 0.4554 - auc: 0.5221\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2439 - precision: 0.5325 - recall: 0.3661 - auc: 0.5746\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5330 - precision: 0.5259 - recall: 0.4308 - auc: 0.5268\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4090 - precision: 0.5190 - recall: 0.5781 - auc: 0.4941\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2360 - precision: 0.5862 - recall: 0.5692 - auc: 0.5758\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8868 - precision: 0.6076 - recall: 0.4665 - auc: 0.6315\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1264 - precision: 0.6079 - recall: 0.5469 - auc: 0.6082\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2954 - precision: 0.5706 - recall: 0.6228 - auc: 0.5823\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[0.47916667 0.6        0.54736842 0.52631579 0.49473684 0.51578947\n",
      " 0.46315789 0.62105263 0.68421053 0.66315789]\n",
      "0.5594956140350876\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(Kclf,X_test,y_test,cv=10,scoring='f1_micro')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5\n",
    "兩者平均"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest與MLP classifier比較：\n",
      "Ttest_indResult(statistic=5.067857837019003, pvalue=8.017875035075134e-05)\n",
      "\n",
      "RandomForest與Keras的MLP classifier比較：\n",
      "Ttest_indResult(statistic=15.56190508865327, pvalue=6.9556326705628475e-12)\n",
      "\n",
      "Keras的MLP classifier與MLP classifier比較：\n",
      "Ttest_indResult(statistic=-11.07866813176535, pvalue=1.8056703732480442e-09)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import scipy.stats\n",
    "\n",
    "print('RandomForest與MLP classifier比較：')\n",
    "print(scipy.stats.ttest_ind(RFscores,MLPscores))\n",
    "\n",
    "print('\\nRandomForest與Keras的MLP classifier比較：')\n",
    "print(scipy.stats.ttest_ind(RFscores,scores))\n",
    "\n",
    "print('\\nKeras的MLP classifier與MLP classifier比較：')\n",
    "print(scipy.stats.ttest_ind(scores,MLPscores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在計算兩兩獨力樣本的平均值t-test並比較中，皆可發現pvalue遠小於0.05表示拒絕相等總體均值的原假設，代表他們並非有過多的極值存在都是效果不錯且結果不會差異太大的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1528</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>0.2095</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>1.5325</td>\n",
       "      <td>7.3388</td>\n",
       "      <td>0.9631</td>\n",
       "      <td>0.7383</td>\n",
       "      <td>0.1325</td>\n",
       "      <td>0.1427</td>\n",
       "      <td>0.1101</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.2539</td>\n",
       "      <td>0.2982</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>2.7235</td>\n",
       "      <td>2.7184</td>\n",
       "      <td>0.1251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1      2       3       4       5       6       7       8   \\\n",
       "0  0.1528  0.0735  0.149  0.0479  0.2095  0.1416  1.5325  7.3388  0.9631   \n",
       "\n",
       "       9       10      11      12      13      14      15      16      17  \\\n",
       "0  0.7383  0.1325  0.1427  0.1101  0.0111  0.2539  0.2982  0.0078  2.7235   \n",
       "\n",
       "       18      19  \n",
       "0  2.7184  0.1251  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf = pd.read_csv('new_data.txt', sep=\",\",header=None)\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest預測結果：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['male'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('RandomForest預測結果：')\n",
    "RFmodel.predict(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP classifier預測結果：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['male'], dtype='<U6')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('MLP classifier預測結果：')\n",
    "MLPmodel.predict(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras的MLP classifier預測結果：\n",
      "1/1 [==============================] - 0s 52ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['male']], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Keras的MLP classifier預測結果：')\n",
    "Kclf.predict(newdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三種模型預測皆為male"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02427566, 0.10490754, 0.0147776 , 0.12865715, 0.00927296,\n",
       "       0.23228776, 0.00900461, 0.0057943 , 0.03426135, 0.02481561,\n",
       "       0.01551234, 0.01846044, 0.3254342 , 0.00815165, 0.00577378,\n",
       "       0.00865816, 0.00645684, 0.00987848, 0.00713401, 0.00648558])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFmodel.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從上方列出的feature重要性來看，第13個屬性**meanfun**最重要"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
